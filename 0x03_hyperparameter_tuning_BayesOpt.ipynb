{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0x03-hyperparameter_tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFTSKte6vuwtEFjVdUueHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svelezg/holbertonschool-machine_learning/blob/master/0x03_hyperparameter_tuning_BayesOpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q49WpLsV99OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "0c62d72f-099d-4600-8317-2751aa16fd65"
      },
      "source": [
        "!pip install GPy==1.9.8\n",
        "!pip install GPyOpt==1.2.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPy==1.9.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/4418ee1db50c6e917e399db841c30b95d3c242555272e85473404ab06377/GPy-1.9.8.tar.gz (989kB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 4.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 4.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 4.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 522kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 532kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 542kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 552kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 563kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 573kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 583kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 593kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 604kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 614kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 624kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 634kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 645kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 655kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 665kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 675kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 686kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 696kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 706kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 716kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 727kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 737kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 747kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 757kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPy==1.9.8) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPy==1.9.8) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy==1.9.8) (1.15.0)\n",
            "Collecting paramz>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/37/4abbeb78d30f20d3402887f46e6e9f3ef32034a9dea65d243654c82c8553/paramz-0.9.5.tar.gz (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy==1.9.8) (4.4.2)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.9.8-cp36-cp36m-linux_x86_64.whl size=2626086 sha256=1c7272dfee6c63f81eb09cb18e91c59957ec75d7e700bd9f8e23ca485614c541\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/ee/cd/1c4dd7df63246b1e8de58af6d4457b7aed13509fdc0c918a13\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-cp36-none-any.whl size=102552 sha256=f97c0a6cf5258c29857511660006aa713f284fd11b957bef1140ac7f8ca65015\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/4a/0e/6e0dc85541825f991c431619e25b870d4b812c911214690cf8\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, GPy\n",
            "Successfully installed GPy-1.9.8 paramz-0.9.5\n",
            "Collecting GPyOpt==1.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/a7/55a77308ce5384f9c0a3dc5eb8b7e26b345219dc4f4831b1bd8688949527/GPyOpt-1.2.1.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPyOpt==1.2.1) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPyOpt==1.2.1) (1.4.1)\n",
            "Requirement already satisfied: GPy>=1.8 in /usr/local/lib/python3.6/dist-packages (from GPyOpt==1.2.1) (1.9.8)\n",
            "Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->GPyOpt==1.2.1) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->GPyOpt==1.2.1) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt==1.2.1) (4.4.2)\n",
            "Building wheels for collected packages: GPyOpt\n",
            "  Building wheel for GPyOpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPyOpt: filename=GPyOpt-1.2.1-cp36-none-any.whl size=73677 sha256=fdd160405cdb3084fce7f9c9a6329abd497350bd4bbfdf41de0fd598a8dc048d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/a2/96/0a5ca8a8de654d567bff2ad6fcb5e8bcdaf15e2366385510cd\n",
            "Successfully built GPyOpt\n",
            "Installing collected packages: GPyOpt\n",
            "Successfully installed GPyOpt-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTAV7fr8OK_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"Contains the build_model function\"\"\"\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "\n",
        "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
        "    \"\"\"\n",
        "    builds a neural network with the Keras library\n",
        "    :param nx: number of input features to the network\n",
        "    :param layers: list containing the number of nodes\n",
        "        in each layer of the network\n",
        "    :param activations: list containing the activation\n",
        "        functions used for each layer of the network\n",
        "    :param lambtha: L2 regularization parameter\n",
        "    :param keep_prob: probability that a node will be kept for dropout\n",
        "    :return: keras model\n",
        "    \"\"\"\n",
        "    # input placeholder\n",
        "    inputs = keras.Input(shape=(nx,))\n",
        "\n",
        "    # regularization scheme\n",
        "    reg = keras.regularizers.L1L2(l2=lambtha)\n",
        "\n",
        "    # a layer instance is callable on a tensor, and returns a tensor.\n",
        "    # first densely-connected layer\n",
        "    my_layer = keras.layers.Dense(units=layers[0],\n",
        "                                  activation=activations[0],\n",
        "                                  kernel_regularizer=reg,\n",
        "                                  input_shape=(nx,))(inputs)\n",
        "\n",
        "    # subsequent densely-connected layers:\n",
        "    for i in range(1, len(layers)):\n",
        "        my_layer = keras.layers.Dropout(1 - keep_prob)(my_layer)\n",
        "        my_layer = keras.layers.Dense(units=layers[i],\n",
        "                                      activation=activations[i],\n",
        "                                      kernel_regularizer=reg,\n",
        "                                      )(my_layer)\n",
        "\n",
        "    network = keras.Model(inputs=inputs, outputs=my_layer)\n",
        "\n",
        "    return network"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEjBgBLEOhbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"Contains the optimize_model function\"\"\"\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "\n",
        "def optimize_model(network, alpha, beta1, beta2):\n",
        "    \"\"\"\n",
        "    sets up Adam optimization for a keras model\n",
        "    with categorical crossentropy loss and accuracy metrics\n",
        "    :param network: model to optimize\n",
        "    :param alpha: learning rate\n",
        "    :param beta1: first Adam optimization parameter\n",
        "    :param beta2: second Adam optimization parameter\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    network.compile(optimizer=keras.optimizers.Adam(alpha, beta1, beta2),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "    return None"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd5Ts2OeOxL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"Contains the one_hot function\"\"\"\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "\n",
        "def one_hot(labels, classes=None):\n",
        "    \"\"\"\n",
        "    converts a label vector into a one-hot matrix\n",
        "    :param labels:\n",
        "    :param classes:\n",
        "    :return: the one-hot matrix\n",
        "    \"\"\"\n",
        "    return keras.utils.to_categorical(\n",
        "        labels, classes)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXlmgoseO6CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"Contains the train_model function\"\"\"\n",
        "\n",
        "import tensorflow.keras as K\n",
        "\n",
        "\n",
        "def train_model(network, data, labels, batch_size, epochs,\n",
        "                validation_data=None,\n",
        "                early_stopping=False, patience=2,\n",
        "                learning_rate_decay=False, alpha=0.1, decay_rate=1,\n",
        "                save_best=False, filepath=None,\n",
        "                verbose=True, shuffle=False):\n",
        "    \"\"\"\n",
        "        trains a model using mini-batch gradient descent\n",
        "        :param network: model to train\n",
        "        :param data: numpy.ndarray of shape (m, nx) containing the input data\n",
        "        :param labels: one-hot numpy.ndarray of shape (m, classes)\n",
        "            containing the labels of data\n",
        "        :param batch_size: size of the batch used for mini-batch grad descent\n",
        "        :param epochs: number of passes through data for mini-batch grad desc\n",
        "        :param validation_data:  data to validate the model with, if not None\n",
        "        :param early_stopping: boolean that indicates whether\n",
        "            early stopping should be used\n",
        "        :param patience: patience used for early stopping\n",
        "        :param learning_rate_decay: boolean that indicates whether\n",
        "            learning rate decay should be used\n",
        "        :param alpha: initial learning rate\n",
        "        :param decay_rate: decay rate\n",
        "        :param save_best: boolean indicating whether to save the model\n",
        "            after each epoch if it is the best\n",
        "        :param filepath: file path where the model should be saved\n",
        "        :param verbose: boolean that determines if output should be printed\n",
        "            during training\n",
        "        :param shuffle: boolean that determines whether to shuffle the batches\n",
        "            every epoch.\n",
        "            Normally, it is a good idea to shuffle,\n",
        "            but for reproducibility, we have chosen to set the default to False\n",
        "        :return: History object generated after training the model\n",
        "        \"\"\"\n",
        "\n",
        "    def learning_rate(epoch):\n",
        "        \"\"\" updates the learning rate using inverse time decay \"\"\"\n",
        "        return alpha / (1 + decay_rate * epoch)\n",
        "\n",
        "    callback_list = []\n",
        "\n",
        "    \n",
        "    # models save callback\n",
        "    if save_best:\n",
        "        mcp_save = K.callbacks.ModelCheckpoint(filepath,\n",
        "                                               save_best_only=True,\n",
        "                                               monitor='val_loss',\n",
        "                                               mode='min')\n",
        "        callback_list.append(mcp_save)\n",
        "    \n",
        "\n",
        "    # learning rate decay callback\n",
        "    if validation_data and learning_rate_decay:\n",
        "        lrd = K.callbacks.LearningRateScheduler(learning_rate,\n",
        "                                                verbose=1)\n",
        "        callback_list.append(lrd)\n",
        "\n",
        "    # early stopping callback\n",
        "    if validation_data and early_stopping:\n",
        "        es = K.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                       mode='min',\n",
        "                                       patience=patience)\n",
        "        callback_list.append(es)\n",
        "\n",
        "    # training\n",
        "    history = network.fit(data,\n",
        "                          labels,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=validation_data,\n",
        "                          verbose=verbose,\n",
        "                          shuffle=shuffle,\n",
        "                          callbacks=callback_list)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apmOVsukO6_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac963454-0b77-4ae5-dd41-d988abec7468"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "best_accuracy = 0.0\n",
        "\n",
        "def F(v, w, x, y, z):\n",
        "\n",
        "    # hyperparameter selection\n",
        "    print('\\n')\n",
        "    print('dense layers\\' units:', int(v))\n",
        "    print('learning rate:', w)\n",
        "    print('batch_size:', int(x))\n",
        "    print('keep_prob:', y)\n",
        "    print('L2 regularization weight (lambtha):', z)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # dataset loading\n",
        "    datasets = np.load('MNIST.npz')\n",
        "    \n",
        "    X_train = datasets['X_train']\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    Y_train = datasets['Y_train']\n",
        "    Y_train_oh = one_hot(Y_train)\n",
        "    X_valid = datasets['X_valid']\n",
        "    X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
        "    Y_valid = datasets['Y_valid']\n",
        "    Y_valid_oh = one_hot(Y_valid)\n",
        "\n",
        "\n",
        "    # create model\n",
        "    lambtha = z\n",
        "    keep_prob = y\n",
        "    model = build_model(784, [v, v, 10],\n",
        "                          ['relu', 'relu', 'softmax'],\n",
        "                          lambtha, keep_prob)\n",
        "\n",
        "    # model optimization\n",
        "    alpha = w\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    optimize_model(model, alpha, beta1, beta2)\n",
        "    batch_size = int(x)\n",
        "    epochs = 4\n",
        "    \n",
        "    filepath = 'model_{}_{}_{}_{}_{}.h5'.format(int(v), w, int(x), int(y*100), z)\n",
        "    #filepath = 'model_{}_{0:.2}_{}_{}_{}.h5'.format(int(v), w, int(x), int(y), int(z))\n",
        "    print(filepath)             \n",
        "                    \n",
        "\n",
        "    history = train_model(model, X_train, Y_train_oh, batch_size, epochs,\n",
        "                validation_data=(X_valid, Y_valid_oh), early_stopping=True,\n",
        "                patience=1, learning_rate_decay=True, alpha=alpha,\n",
        "                save_best=True, filepath=filepath)\n",
        "   \n",
        "\n",
        "    # Get the classification accuracy on the validation-set\n",
        "    # after the last training-epoch.\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "    # Print the classification accuracy.\n",
        "    print()\n",
        "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
        "    print()\n",
        "\n",
        "    # Save the model if it improves on the best-found performance.\n",
        "    # We use the global keyword so we update the variable outside\n",
        "    # of this function.\n",
        "    global best_accuracy\n",
        "\n",
        "    path_best_model='best.h5'\n",
        "\n",
        "    # If the classification accuracy of the saved model is improved ...\n",
        "    if accuracy > best_accuracy:\n",
        "        # Save the new model to harddisk.\n",
        "        model.save(path_best_model)\n",
        "        \n",
        "        # Update the classification accuracy.\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "    # Delete the Keras model with these hyper-parameters from memory.\n",
        "    del model\n",
        "    \n",
        "    # Clear the Keras session, otherwise it will keep adding new\n",
        "    # models to the same TensorFlow graph each time we create\n",
        "    # a model with a different set of hyper-parameters.\n",
        "    K.backend.clear_session()\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def f(X):\n",
        "  Y = np.zeros((X.shape[0], 1))\n",
        "  for i in range(X.shape[0]):\n",
        "    Y[i] = F(X[i][0], 10 ** (X[i][1]), X[i][2],\n",
        "            X[i][3], 10 ** X[i][4]\n",
        "             )\n",
        "    \n",
        "  return(Y)\n",
        "  \n",
        "\n",
        "X_init = np.array([[int(16), -5, int(8), 0.5, -8],\n",
        "                   [int(32), -4, int(128), 0.75, -5]])\n",
        "Y_init = f(X_init)\n",
        "\n",
        "print('X_init', X_init)\n",
        "print('Y_init', Y_init)   "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "dense layers' units: 16\n",
            "learning rate: 1e-05\n",
            "batch_size: 8\n",
            "keep_prob: 0.5\n",
            "L2 regularization weight (lambtha): 1e-08\n",
            "model_16_1e-05_8_50_1e-08.h5\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 2.2605 - accuracy: 0.1495 - val_loss: 2.1445 - val_accuracy: 0.3624\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 5e-06.\n",
            "Epoch 2/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 2.1664 - accuracy: 0.2030 - val_loss: 2.0597 - val_accuracy: 0.4288\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 3.3333333333333337e-06.\n",
            "Epoch 3/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 2.1263 - accuracy: 0.2164 - val_loss: 2.0079 - val_accuracy: 0.4603\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 2.5e-06.\n",
            "Epoch 4/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 2.0951 - accuracy: 0.2313 - val_loss: 1.9657 - val_accuracy: 0.4824\n",
            "\n",
            "Accuracy: 48.24%\n",
            "\n",
            "\n",
            "\n",
            "dense layers' units: 32\n",
            "learning rate: 0.0001\n",
            "batch_size: 128\n",
            "keep_prob: 0.75\n",
            "L2 regularization weight (lambtha): 1e-05\n",
            "model_32_0.0001_128_75_1e-05.h5\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 1/4\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.9269 - accuracy: 0.3525 - val_loss: 1.2320 - val_accuracy: 0.7644\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 5e-05.\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 1.3159 - accuracy: 0.5916 - val_loss: 0.9025 - val_accuracy: 0.8241\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 3.3333333333333335e-05.\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.1471 - accuracy: 0.6420 - val_loss: 0.7776 - val_accuracy: 0.8464\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 2.5e-05.\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 1s 4ms/step - loss: 1.0662 - accuracy: 0.6646 - val_loss: 0.7082 - val_accuracy: 0.8556\n",
            "\n",
            "Accuracy: 85.56%\n",
            "\n",
            "X_init [[ 16.    -5.     8.     0.5   -8.  ]\n",
            " [ 32.    -4.   128.     0.75  -5.  ]]\n",
            "Y_init [[0.4824]\n",
            " [0.8556]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo039WZ8-C35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "bbed032c-9a85-46dc-919a-6a76a66b010d"
      },
      "source": [
        "import GPy\n",
        "import GPyOpt\n",
        "%matplotlib inline\n",
        "\n",
        "from GPyOpt.methods import BayesianOptimization\n",
        "\n",
        "kernel = GPy.kern.Matern52(input_dim=5, variance=1.0, lengthscale=1.0)\n",
        "bds = [\n",
        "       {'name': 'units', 'type': 'discrete', 'domain': (256/16, 256*4)},\n",
        "       {'name': 'learning rate', 'type': 'discrete', 'domain': (-5, -2)},\n",
        "       {'name': 'batch_size', 'type': 'discrete', 'domain': (64/8, 64*2)},\n",
        "       {'name': 'keep_prob', 'type': 'continuous', 'domain': (0.5, 1)},\n",
        "       {'name': 'lambtha', 'type': 'discrete', 'domain': (-5, -8)},\n",
        "       ]\n",
        "\n",
        "\n",
        "optimizer = BayesianOptimization(f=f, \n",
        "                                 domain=bds,\n",
        "                                 model_type='GP',\n",
        "                                 kernel=kernel,\n",
        "                                 acquisition_type ='EI',\n",
        "                                 acquisition_jitter = 0.01,\n",
        "                                 X=X_init,\n",
        "                                 Y=-Y_init,\n",
        "                                 #noise_var = noise**2,\n",
        "                                 exact_feval=False,\n",
        "                                 normalize_Y=False,\n",
        "                                 maximize=True,\n",
        "                                 verbosity=True,\n",
        "                                 report_file='bayes_opt.txt')\n",
        "\n",
        "optimizer.run_optimization(max_iter=2)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "dense layers' units: 16\n",
            "learning rate: 1e-05\n",
            "batch_size: 8\n",
            "keep_prob: 0.508801765839342\n",
            "L2 regularization weight (lambtha): 1e-08\n",
            "model_16_1e-05_8_50_1e-08.h5\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 2.2981 - accuracy: 0.1255 - val_loss: 2.2110 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 5e-06.\n",
            "Epoch 2/4\n",
            "6250/6250 [==============================] - 16s 3ms/step - loss: 2.2187 - accuracy: 0.1717 - val_loss: 2.1501 - val_accuracy: 0.4136\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 3.3333333333333337e-06.\n",
            "Epoch 3/4\n",
            "6250/6250 [==============================] - 16s 3ms/step - loss: 2.1856 - accuracy: 0.1879 - val_loss: 2.1080 - val_accuracy: 0.4551\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 2.5e-06.\n",
            "Epoch 4/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 2.1573 - accuracy: 0.2069 - val_loss: 2.0746 - val_accuracy: 0.4753\n",
            "\n",
            "Accuracy: 47.53%\n",
            "\n",
            "\n",
            "\n",
            "dense layers' units: 16\n",
            "learning rate: 0.01\n",
            "batch_size: 8\n",
            "keep_prob: 0.5\n",
            "L2 regularization weight (lambtha): 1e-08\n",
            "model_16_0.01_8_50_1e-08.h5\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
            "Epoch 1/4\n",
            "6250/6250 [==============================] - 17s 3ms/step - loss: 1.7123 - accuracy: 0.3637 - val_loss: 1.1338 - val_accuracy: 0.6345\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.005.\n",
            "Epoch 2/4\n",
            "6250/6250 [==============================] - 16s 3ms/step - loss: 1.6053 - accuracy: 0.3904 - val_loss: 1.0529 - val_accuracy: 0.6454\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0033333333333333335.\n",
            "Epoch 3/4\n",
            "6250/6250 [==============================] - 16s 3ms/step - loss: 1.5911 - accuracy: 0.3931 - val_loss: 1.0588 - val_accuracy: 0.6519\n",
            "\n",
            "Accuracy: 65.19%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzGZCNOuOnT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "d603ef9e-f6b1-496d-8d93-bbf96a768404"
      },
      "source": [
        "optimizer.plot_acquisition()\n",
        "optimizer.plot_convergence()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu1bP8kesmvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6671aa42-af05-457a-b5cb-8cad76a63d81"
      },
      "source": [
        "optimizer.save_evaluations(evaluations_file='bayes_opt.txt')\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"Max Val accuracy:  {0:.1%}\".format(-optimizer.fx_opt[0])) \n",
        "print(\"Hyperparmeters' values that maximize the objective:\"+str(optimizer.x_opt))    \n",
        "    \n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "for i in range(optimizer.Y.shape[0]):\n",
        "  \n",
        "  print(\"Acc: {0:.1%}\".format(-optimizer.Y[i][0]),\n",
        "        \"[\" \n",
        "        \"{0:.2}\".format(optimizer.X[i][0]),\n",
        "        int(optimizer.X[i][1]),\n",
        "        \"{0:.2}\".format(optimizer.X[i][2]),\n",
        "        \"{}\".format(optimizer.X[i][3]),\n",
        "        int(optimizer.X[i][4]),\n",
        "        \"]\"\n",
        "        \n",
        "        )\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Max Val accuracy:  88.6%\n",
            "Hyperparmeters' values that maximize the objective:[ 32.    -4.   128.     0.75  -5.  ]\n",
            "====================================================================================================\n",
            "\n",
            "Acc: 49.8% [1.6e+01 -5 8.0 0.5 -8 ]\n",
            "Acc: 88.6% [3.2e+01 -4 1.3e+02 0.75 -5 ]\n",
            "Acc: 55.1% [1.6e+01 -5 8.0 0.5060793743796895 -8 ]\n",
            "Acc: 63.0% [1.6e+01 -5 8.0 0.6575468187378135 -8 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}